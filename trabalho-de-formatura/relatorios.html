<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relatórios</title>
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato&display=swap">
</head>
<body>
<h2 id="pesquisa">Pesquisa</h2>
<h3 id="relatorio-do-primeiro-semestre">Relatório do Primeiro Semestre</h3>
<p>A pesquisa inicial propunha a investigação de <em>embeddings</em> e busca vetorial e sua utilização na criação de sistemas de busca semânticos. Como resultado da pesquisa, eu pretendo criar um sistema de busca semântico para o sistema de busca de teses da USP, disponível em <a href="https://teses.usp.br/">https://teses.usp.br/</a>. O sistema de busca deve envolver texto e imagem. Quando se lê, abaixo, sobre texto, o mesmo vale para imagem.</p>
<h4 id="por-que-um-sistema-de-busca-sem-ntico-">Por que um sistema de busca semântico?</h4>
<p>Minha suposição inicial é de que um sistema de busca semântico é melhor para buscar textos do que sistemas tradicionais de busca, principalmente quando envolve recuperação de conhecimento. Quando recuperar conhecimento envolve a combinação de palavras e a busca dessas palavras em textos, um sistema deve considerar o sentido semântico de cada palavra individual, o contexto da busca, o sentido semântico de todas as palavras juntas. Em um sistema comum de recuperação de conhecimento, existem heurísticas de busca por frequência de palavras em um texto para recuperá-lo, o que não é suficiente para conseguir um resultado de busca relevante.</p>
<h4 id="o-que-s-o-_embeddings_-e-por-que-utiliz-los-">O que são <em>embeddings</em> e por que utilizá-los?</h4>
<p>São formas de representar texto com números, através da codificação desse texto. Diferentemente de outros métodos de codificação de texto, embeddings conseguem representar relacionamentos entre palavras e sua codificação ajuda em sua utilização em algoritmos de aprendizagem de máquina. Com embeddings, a similaridade semântica entre dois textos pode ser computada de forma trivial por meio do produto interno de suas representações.</p>
<p>Embeddings são gerados a partir de um modelo de aprendizagem de máquina. Esses modelos são treinados com bilhões ou mais de um trilhão de palavras obtidas da internet. Eles resultam em algo semelhante a uma tabela, capazes de receber texto como input e retornar uma representação vetorial desse texto. Esses modelos são treinados para serem capazes de generalizar para uma ampla gama de textos, de várias áreas, mas é possível ajustar tais modelos para gerar melhores representações para os dados com que se está trabalhando. Ajuste fino de um modelo (fine-tuning) é o processo de ajustar um modelo para trabalhar com dados de um domínio específico. A forma de avaliar um modelo que gera embeddings de texto é por MSMARCO Passage Ranking ou STS (Semantic Textual Similarity) Benchmark. A forma de avaliar um modelo ajustado tem a mesma ideia: precisa-se de uma tarefa para resolver e que essa tarefa seja avaliada com base em um resultado conhecido.</p>
<p>Referências: </p>
<ul>
<li><a href="https://www.tensorflow.org/text/guide/word_embeddings">https://www.tensorflow.org/text/guide/word_embeddings</a> </li>
<li><a href="https://sbert.net/">https://sbert.net/</a></li>
<li><a href="https://huggingface.co/tasks/sentence-similarity">https://huggingface.co/tasks/sentence-similarity</a></li>
<li><a href="https://dev.to/meetkern/how-to-fine-tune-your-embeddings-for-better-similarity-search-445e">https://dev.to/meetkern/how-to-fine-tune-your-embeddings-for-better-similarity-search-445e</a></li>
</ul>
<h4 id="o-que-uma-busca-vetorial-">O que é uma busca vetorial?</h4>
<p>A busca de texto por meio de embeddings envolve a geração de embeddings de todo o domínio de busca, a geração de embedding do texto que se deseja buscar e a busca vetorial deste último no domínio de busca. A busca vetorial é um método usado para encontrar vetores em um espaço multidimensional. Para isso, é feita uma busca de similaridade entre a representação vetorial do texto buscado e os demais vetores no espaço de busca. Esse método de busca é conhecido como Nearest Neighbors. A ideia da busca é encontrar o vetor mais próximo do vetor de busca. Isso, entretanto, pode ser custoso quando o espaço de busca é muito grande. Alguns algoritmos e estruturas de dados podem ser utilizados para realizar busca de similaridade em grande conjuntos de vetores, como o Approximate Nearest Neighbors (ANN). Bases de dados vetoriais são conhecidas por implementar algoritmos e estruturas para busca eficiente de vetores.</p>
<p>Referências:</p>
<ul>
<li><a href="http://simsearch.yury.name/">http://simsearch.yury.name/</a></li>
<li><a href="https://github.com/currentslab/awesome-vector-search">https://github.com/currentslab/awesome-vector-search</a></li>
</ul>
<h4 id="como-avaliar-um-sistema-de-busca-">Como avaliar um sistema de busca?</h4>
<p>Uma forma eficiente de avaliar é classificar os melhores resultados para buscas específicas e medir a qualidade dos resultados baseados em scores para o ranqueamento. Uma boa forma de testar isso é com Discounted Cumulative Gain. DCG mede um ganho baseado na posição da recuperação do documento relevante de uma busca.</p>
<p>Referências:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval">https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval</a>)</li>
<li><a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">https://en.wikipedia.org/wiki/Discounted_cumulative_gain</a></li>
</ul>
<h3 id="relat-rio-dos-experimentos">Relatório dos Experimentos</h3>
<p>Ao longo do semestre eu realizei alguns experimentos com embeddings e com buscas vetoriais, usando dados coletados do site de teses da USP. A forma de coleta de dados foi por um raspador, o código fonte pode ser encontrado em &quot;src&quot; no repositório do sbsd. Os experimentos podem ser encontrados no diretório &quot;experiments&quot; no repositório do sbsd.</p>
<h4 id="experimento-1">Experimento 1</h4>
<p>No primeiro experimento que realizei, tentei usar toda a informação de alguns .pdfs selecionados das teses para criar embeddings. Além de ter sido demorado para criar cada um embedding, a criação de um embedding por documento se mostrou insatisfatória para a busca, dada que muita informação era perdida, além de que o documento tinha muita sujeira, o que exige trabalho extra de limpeza manual. Essa abordagem resultou em um sistema lento para ser criado e trabalhoso. Ou seja, não resultou em um bom sistema para fazer a busca.</p>
<h4 id="experimento-2">Experimento 2</h4>
<p>No segundo experimento que realizei, usei apenas as informações de metadados contidas no site de teses, sem utilizar a tese em si. Os metadados são título, resumo e palavras-chave. Juntei esses 3 em um texto só para gerar cada embedding. O tempo de criação de tudo é em torno de alguns minutos. Com isso, fui capaz de criar um sistema de busca que abarcava todas as teses do site de tese da USP. O sistema foi capaz de obter resultados em menos de 1 segundo. Entretanto, notou-se que a busca foi insatisfatória em algumas instâncias. </p>
<p>Para demonstrar isso, estabeleci o texto de busca &quot;ddos attack&quot;. A busca encontrou o vetor mais similar em 0.19s e o resultado retornado foi:</p>
<pre><code><span class="hljs-number">1.</span> Title:  Mitigating DDoS attacks <span class="hljs-keyword">on</span> IoT <span class="hljs-keyword">through</span> machine learning <span class="hljs-keyword">and</span> network functions virtualization
Author:  Oliveira, Guilherme Werneck de
</code></pre><p>Minha suposição é de que, se esse valor retornado é o mais relevante para &quot;ddos attack&quot;, ele deve também ser o mais relevante, ou pelo menos perder para algum mais relevante ainda, para &quot;ddos attack and machine learning&quot;. Mas não foi isso que aconteceu, ao buscar por &quot;ddos attack and machine learning&quot;, a busca encontrou:</p>
<pre><code><span class="hljs-number">1.</span> Title:  Machine learning <span class="hljs-keyword">in</span> complex networks
Author:  Breve, Fabricio Aparecido
<span class="hljs-number">2.</span> Title:  Architecture <span class="hljs-keyword">and</span> development <span class="hljs-keyword">of</span> a <span class="hljs-built_in">real</span>-<span class="hljs-built_in">time</span> multiple content generator system <span class="hljs-keyword">for</span> video games
Author:  Pereira, Leonardo Tortoro
<span class="hljs-number">3.</span> Title:  Performance prediction <span class="hljs-keyword">of</span> <span class="hljs-built_in">application</span> executed <span class="hljs-keyword">on</span> GPUs using a simple analytical model <span class="hljs-keyword">and</span> machine learning techniques
Author:  González, Marcos Tulio Amarís
<span class="hljs-number">4.</span> Title:  Mitigating DDoS attacks <span class="hljs-keyword">on</span> IoT <span class="hljs-keyword">through</span> machine learning <span class="hljs-keyword">and</span> network functions virtualization
Author:  Oliveira, Guilherme Werneck de
</code></pre><p>Mesmo que sem utilizar métodos formais de avaliação, nota-se que o sistema de busca não foi relevante ao buscar por &quot;ddos attack and machine learning&quot;. Minha suposição é de que muita informação era perdida ao criar um único embedding para todos os metadados.</p>
<h4 id="experimento-3">Experimento 3</h4>
<p>No terceiro experimento que realizei, utilizei os mesmos metadados, mas decidi criar os embeddings a partir de cada sentença, e não usando todos os metadados ao mesmo tempo. Essa abordagem resultou em buscas em torno de 50 vezes mais lentas, mas bem mais relevantes.</p>
<p>Considere novamente o texto &quot;ddos attack&quot;. A busca demorou 4s e o resultado foi:</p>
<pre><code><span class="hljs-number">1</span>. Title:  <span class="hljs-function"><span class="hljs-keyword">Method</span> <span class="hljs-title">for</span> <span class="hljs-title">mitigating</span> <span class="hljs-title">against</span> <span class="hljs-title">distributed</span> <span class="hljs-title">denial</span> <span class="hljs-title">of</span> <span class="hljs-title">service</span> <span class="hljs-title">attacks</span> <span class="hljs-title">using</span> <span class="hljs-title">multi</span>-<span class="hljs-title">agent</span> <span class="hljs-title">system</span>.
<span class="hljs-title">Author</span>:</span>  Pereira, João Paulo Aragão (Catálogo USP)
<span class="hljs-number">2</span>. Title:  A collaborative architecture against DDOS attacks <span class="hljs-keyword">for</span> cloud computing systems.
Author:  Almeida, Thiago Rodrigues Meira de (Catálogo USP)
<span class="hljs-number">3</span>. Title:  Mitigating DDoS attacks <span class="hljs-keyword">on</span> IoT through machine learning <span class="hljs-keyword">and</span> network functions virtualization
Author:  Oliveira, Guilherme Werneck de (Catálogo USP)
</code></pre><p>Comparado ao resultado anterior, eu consideraria que esses resultados foram tão relevantes quanto para essa busca genérica específica. Para saber mais, eu precisaria comparar os 15 primeiros resultados, por exemplo.</p>
<p>Como segundo teste, busquei o texto &quot;ddos attack and machine learning&quot; e o resultado foi:</p>
<pre><code><span class="hljs-number">1.</span> Title:  Mitigating DDoS attacks <span class="hljs-keyword">on</span> IoT <span class="hljs-keyword">through</span> machine learning <span class="hljs-keyword">and</span> network functions virtualization
Author:  Oliveira, Guilherme Werneck de (Catálogo USP)
<span class="hljs-number">2.</span> Title:  Reconfigurable learning system <span class="hljs-keyword">for</span> classification <span class="hljs-keyword">of</span> data using parallel processing
Author:  Moreira, Eduardo Marmo (Catálogo USP)
<span class="hljs-number">3.</span> Title:  A collaborative architecture <span class="hljs-keyword">against</span> DDOS attacks <span class="hljs-keyword">for</span> cloud computing systems.
Author:  Almeida, Thiago Rodrigues Meira de (Catálogo USP)
</code></pre><p>Ou seja, pode-se considerar que houve uma melhora considerável de relevância para essa busca específica.</p>
<h4 id="conclus-o-preliminar-dos-experimentos">Conclusão Preliminar dos Experimentos</h4>
<p>Preliminarmente, notou-se um trade-off entre a qualidade da busca e o tempo levado para buscar e criar o sistema. O sistema que tomou mais para buscar e para criar o sistema resultou em uma qualidade de busca maior. A ideia é que esse sistema seja melhorado em duas frentes, embeddings e busca vetorial. Espera-se que os embeddings resultem em uma maior relevância do resultado de busca e que a busca vetorial resulte em uma maior eficiência (considerando a velocidade do sistema). Afinal, espera-se que um sistema de busca eficiente na web seja capaz de retornar buscas relevantes de forma rápida.</p>
<h4 id="pr-ximos-passos">Próximos Passos</h4>
<p>O primeiro passos a partir de agora é estabelecer uma forma de avaliação da busca, para entender como o sistema pode melhorar. Como referência: <a href="https://opensearch.org/blog/semantic-science-benchmarks/">https://opensearch.org/blog/semantic-science-benchmarks/</a></p>
<p>Passos seguintes envolvem melhorar a busca de uma das seguintes formas:</p>
<ul>
<li>Ajustando o modelo para os dados que eu possuo;</li>
<li>Usar mais dados, considerando os documentos .pdf para que a busca possa abranger mais informações de dentro do texto;</li>
<li>Usar bases de dados vetoriais para a busca.</li>
</ul>
<h3 id="outras-refer-ncias-encontradas">Outras referências encontradas</h3>
<ul>
<li><a href="https://www.deepset.ai/blog/the-beginners-guide-to-text-embeddings">https://www.deepset.ai/blog/the-beginners-guide-to-text-embeddings</a></li>
<li><a href="https://www.elastic.co/blog/how-to-deploy-nlp-text-embeddings-and-vector-search">https://www.elastic.co/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</a></li>
<li><a href="https://platform.openai.com/docs/guides/embeddings">https://platform.openai.com/docs/guides/embeddings</a></li>
<li><a href="https://rom1504.medium.com/semantic-search-with-embeddings-index-anything-8fb18556443c">https://rom1504.medium.com/semantic-search-with-embeddings-index-anything-8fb18556443c</a></li>
<li><a href="https://towardsdatascience.com/beyond-ctrl-f-44f4bec892e9">https://towardsdatascience.com/beyond-ctrl-f-44f4bec892e9</a></li>
<li><a href="https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb">https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb</a></li>
<li><a href="https://dev.to/mage_ai/how-to-build-a-search-engine-with-word-embeddings-56jd">https://dev.to/mage_ai/how-to-build-a-search-engine-with-word-embeddings-56jd</a></li>
<li><a href="https://huggingface.co/course/chapter5/6?fw=tf">https://huggingface.co/course/chapter5/6?fw=tf</a></li>
<li><a href="https://catalog.workshops.aws/semantic-search/en-US/module-1-understand-internal/semantic-search-technology">https://catalog.workshops.aws/semantic-search/en-US/module-1-understand-internal/semantic-search-technology</a></li>
<li>Extending Full Text Search for Legal Document Collections Using Word Embeddings</li>
<li><a href="https://www.scribd.com/document/492791276/Using-Word-Embeddings-for-Text-Search1">https://www.scribd.com/document/492791276/Using-Word-Embeddings-for-Text-Search1</a></li>
<li><a href="https://blog.dataiku.com/semantic-search-an-overlooked-nlp-superpower">https://blog.dataiku.com/semantic-search-an-overlooked-nlp-superpower</a></li>
<li><a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/">https://simonwillison.net/2023/Jan/13/semantic-search-answers/</a></li>
<li><a href="https://www.buildt.ai/blog/3llmtricks">https://www.buildt.ai/blog/3llmtricks</a></li>
<li><a href="https://www.algolia.com/blog/ai/what-is-vector-search/https://qdrant.tech/benchmarks/?gclid=CjwKCAjw__ihBhADEiwAXEazJtsrttmfhWQWIx-xZ2cATXTa2Omoc8RczL_6Bk1NnX_BmNND33xWoxoCqjAQAvD_BwE">https://www.algolia.com/blog/ai/what-is-vector-search/https://qdrant.tech/benchmarks/?gclid=CjwKCAjw__ihBhADEiwAXEazJtsrttmfhWQWIx-xZ2cATXTa2Omoc8RczL_6Bk1NnX_BmNND33xWoxoCqjAQAvD_BwE</a></li>
<li><a href="https://cloud.google.com/vertex-ai/docs/matching-engine/overview">https://cloud.google.com/vertex-ai/docs/matching-engine/overview</a></li>
<li><a href="https://developer.huawei.com/consumer/en/doc/development/hiai-Guides/text-embedding-0000001055002819">https://developer.huawei.com/consumer/en/doc/development/hiai-Guides/text-embedding-0000001055002819</a></li>
<li><a href="https://applyingml.com/resources/search-query-matching/">https://applyingml.com/resources/search-query-matching/</a></li>
<li><a href="https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433">https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433</a></li>
<li>Modern Information Retrieval: The Concepts and Technology behind Search</li>
<li>Word embedding based generalized language model for information retrieval</li>
<li>Embedding-based Query Language Models</li>
<li>Lbl2Vec: an embedding-based approach for unsupervised document retrieval on predefined topics</li>
<li>Neural embedding-based indices for semantic search</li>
<li>Embedding-based news recommendation for millions of users</li>
<li>Divide and Conquer: Towards Better Embedding-based Retrieval for Recommender Systems From a Multi-task Perspective</li>
<li>Embedding based on function approximation for large scale image search</li>
<li>Pre-training Tasks for Embedding-based Large-scale Retrieval</li>
<li>QuadrupletBERT: An Efficient Model For Embedding-Based Large-Scale  Retrieval</li>
<li>A text-embedding-based approach to measuring patent-to-patent technological similarity</li>
</ul>
<p>Victor Lempitsky. 2012. The Inverted Multi-Index. In Proceedings of the 2012 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR) (CVPR ’12). IEEE
Computer Society, USA, 3069–3076.</p>
<p>Hang Li and Jun Xu. 2014. Semantic Matching in Search. Now Publishers Inc.,
Hanover, MA, USA.</p>
<p>Bhaskar Mitra and Nick Craswell. 2018. An Introduction to Neural Information
Retrieval. Foundations and Trends® in Information Retrieval 13, 1 (December
2018), 1–126.</p>
<p>Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, and Philipp Krähenbühl. 2017.
Sampling Matters in Deep Embedding Learning. CoRR abs/1706.07567 (2017).
arXiv:1706.07567 <a href="http://arxiv.org/abs/1706.07567">http://arxiv.org/abs/1706.07567</a></p>

</body>
</html>